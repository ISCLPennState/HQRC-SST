{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# # -*- coding: utf-8 -*-\n",
    "#!/usr/bin/env python\n",
    "#!pip install tensorflow==1.15\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob, os, inspect\n",
    "import argparse\n",
    "import time\n",
    "import seaborn as sns\n",
    "# import matplotlib\n",
    "# matplotlib.use(\"Qt5Agg\")\n",
    "# #matplotlib.use('Agg')\n",
    "# from mpl_toolkits.mplot3d import axes3d\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys,inspect\n",
    "sys.path.append(\"C:\\\\Users\\\\Vinamr J\\\\Documents\\\\qic\\\\qrc\\\\hqr\\\\hqr-master\\\\chaos\\\\Postprocess\")\n",
    "sys.path.append(\"C:\\\\Users\\\\Vinamr J\\\\Documents\\\\qic\\\\qrc\\\\hqr\\\\hqr-master\\\\chaos\\\\Methods\\\\Models\\\\Utils\")\n",
    "\n",
    "import utils  # for utils.py\n",
    "from utils import *\n",
    "import global_utils  # for global_utils.py\n",
    "\n",
    "# import utils\n",
    "# from utils import *\n",
    "# import sys\n",
    "# sys.path.append('../Methods/Models/Utils')\n",
    "# import global_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\Users\\Vinamr J\\Documents\\qic\\qrc\\hqr\\hqr-master\\chaos\\Data\\SST\n",
      "Parent Directory: c:\\Users\\Vinamr J\\Documents\\qic\\qrc\\hqr\\hqr-master\\chaos\n",
      "c:\\Users\\Vinamr J\\Documents\\qic\\qrc\\hqr\\hqr-master\\chaos\\Results\n",
      "c:\\Users\\Vinamr J\\Documents\\qic\\qrc\\hqr\\hqr-master\\chaos\\Results\\SST\\Evaluation_Data\n",
      "c:\\Users\\Vinamr J\\Documents\\qic\\qrc\\hqr\\hqr-master\\chaos\\Results\\SST\\Trained_Models\n",
      "c:\\Users\\Vinamr J\\Documents\\qic\\qrc\\hqr\\hqr-master\\chaos\\Results\\SST\\Eval_Figures\n"
     ]
    }
   ],
   "source": [
    "sysname, tidx = \"SST\", 2\n",
    "file_path = os.path.abspath(\"ESN_analysis.ipynb\")\n",
    "current_directory = os.path.dirname(file_path)\n",
    "mid_directory = os.path.dirname(current_directory)\n",
    "parent_directory = os.path.dirname(mid_directory)\n",
    "\n",
    "print(\"Current Directory:\", current_directory)\n",
    "print(\"Parent Directory:\", parent_directory)\n",
    "\n",
    "#current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "results_dir = os.path.join(os.path.dirname(mid_directory), \"Results\")  # Use os.path.join for path concatenation\n",
    "print(results_dir)\n",
    "\n",
    "eval_path = os.path.join(results_dir, sysname, 'Evaluation_Data')\n",
    "print(eval_path)\n",
    "\n",
    "model_path = os.path.join(results_dir, sysname, 'Trained_Models')\n",
    "print(model_path)\n",
    "\n",
    "fig_path = os.path.join(results_dir, sysname, 'Eval_Figures')\n",
    "if not os.path.isdir(fig_path):\n",
    "    os.makedirs(fig_path)  # Use os.makedirs to create parent directories if needed\n",
    "print(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "samples = []\n",
    "size_values = [40, 60, 80, 100, 120, 150, 200, 300, 500, 1000]\n",
    "for size in size_values:\n",
    "    string1 = f\"ESN_pinv-RDIM_5-N_used_427-SIZE_{size}-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3\"\n",
    "    string2 = f\"ESN-{size}\"\n",
    "    models.append([os.path.join(eval_path,string1),string2])\n",
    "    samples.append(string2)\n",
    "title = \"Sea Surface Temperatures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [[os.path.join(eval_path, \"hqrc_pinv-RDIM_5-N_used_427-DL_40-Nqr_5-A_0.9-J_2.0-fJ_1-V_10-NL_0-IPL_20-IUL_0-REG_1e-07-AU_0-NICS_3\"),\"HQR-5,V-10,DL=40,IPL=20,n_tests=3\"],\n",
    "#           [os.path.join(eval_path, \"hqrc_pinv-RDIM_5-N_used_427-DL_8-Nqr_5-A_0.9-J_2.0-fJ_1-V_10-NL_0-IPL_8-IUL_0-REG_1e-07-AU_0-NICS_1\"),\"HQR-5,V-10,DL=8,IPL=8,n_tests=1\"],\n",
    "#           [os.path.join(eval_path, \"hqrc_pinv-RDIM_5-N_used_427-DL_40-Nqr_5-A_0.9-J_2.0-fJ_1-V_10-NL_0-IPL_300-IUL_0-REG_1e-07-AU_0-NICS_1\"),\"HQR-5,V-10,DL=40,IPL=300,n_tests=1\"]]\n",
    "# samples = [\"HQR-5,V-10,DL=40,IPL=20,n_tests=3\",\"HQR-5,V-10,DL=8,IPL=8,n_tests=1\",\"HQR-5,V-10,DL=40,IPL=300,n_tests=1\"]\n",
    "# title = \"Sea Surface Temperatures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_40-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_60-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_80-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_100-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_120-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_150-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_200-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_300-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_500-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n",
      "(3, 300, 5)\n",
      "ESN_pinv-RDIM_5-N_used_427-SIZE_1000-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3 Number of test 3\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "rmse_dict = dict()\n",
    "targets = dict()\n",
    "outputs = dict()\n",
    "sp_outputs = dict()\n",
    "sp_targets = dict()\n",
    "Wouts = dict()\n",
    "coeffs = dict()\n",
    "rmnse_avg_train_dict = dict()\n",
    "rmnse_avg_test_dict = dict()\n",
    "for i in range(len(models)):\n",
    "    rfolder, label = models[i][0], models[i][1]\n",
    "    fname = os.path.join(rfolder, 'results.pickle')\n",
    "    if os.path.isfile(fname):\n",
    "        with open(fname, 'rb') as rfile:\n",
    "            try:\n",
    "                rs = pickle.load(rfile)\n",
    "            except:\n",
    "                continue\n",
    "            #print(rs.keys())\n",
    "            qs = QResults()\n",
    "            qs.rmnse_avg_test = rs['rmnse_avg_TEST']\n",
    "            qs.rmnse_avg_train = rs['rmnse_avg_TRAIN']\n",
    "            qs.n_pred_005_avg_test = rs['num_accurate_pred_005_avg_TEST']\n",
    "            qs.n_pred_005_avg_train = rs['num_accurate_pred_005_avg_TRAIN']\n",
    "            qs.n_pred_050_avg_test = rs['num_accurate_pred_050_avg_TEST']\n",
    "            qs.n_pred_050_avg_train = rs['num_accurate_pred_050_avg_TRAIN']\n",
    "            qs.model_name = rs['model_name']\n",
    "            #if qs.rmnse_avg_test != np.inf and qs.rmnse_avg_train != np.inf:\n",
    "                #print(rs.keys())\n",
    "            #print(qs.model_name)\n",
    "            #print('train={}, test={}'.format(qs.rmnse_avg_train, qs.rmnse_avg_test))\n",
    "            #qs.info()\n",
    "            rmnse_avg_train_dict[label] = rs['rmnse_avg_TRAIN']\n",
    "            rmnse_avg_test_dict[label] = rs['rmnse_avg_TEST']\n",
    "            pred_test = rs['predictions_all_TEST']\n",
    "            truth_test = rs['truths_all_TEST']\n",
    "            print(pred_test.shape)\n",
    "            M = len(pred_test)\n",
    "            print('{} Number of test'.format(qs.model_name), M)\n",
    "            rmsels = []\n",
    "            for j in range(M):\n",
    "                    rmsels.append(calNRMSE(pred_test[j], truth_test[j]))\n",
    "\n",
    "            rmse_dict[label] = np.mean(np.array(rmsels), axis=0)\n",
    "            print(rmse_dict[label].shape)\n",
    "\n",
    "\n",
    "            targets[label] = truth_test[0]\n",
    "            outputs[label] = pred_test[0]\n",
    "\n",
    "            # For frequency\n",
    "            sp_outputs[label] = rs['sp_pred_TEST']\n",
    "            sp_targets[label] = rs['sp_true_TEST']\n",
    "    else:\n",
    "        print('Not found {}'.format(fname))\n",
    "    # if trained_models is not None:\n",
    "    #     rfolder, label = trained_models[i][0], trained_models[i][1]\n",
    "    #     fname = os.path.join(rfolder, 'data.pickle')\n",
    "    #     if os.path.isfile(fname):\n",
    "    #         print('File existed: ', fname)\n",
    "    #         with open(fname, 'rb') as rfile:\n",
    "    #             #try:\n",
    "    #             rs = pickle.load(rfile)\n",
    "    #             #except:\n",
    "    #             #    continue\n",
    "    #             print(rs.keys())\n",
    "    #             coeffs[label] = np.array(rs['coeffs'])\n",
    "    #             Wouts[label]  = rs['W_out'][:-1].reshape((coeffs[label].shape[0], -1))\n",
    "    #             print(Wouts[label].shape, coeffs[label].shape)\n",
    "    #     else:\n",
    "    #         print('Not found saved model {}'.format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ESN-40', 1.6130774555297716], ['ESN-60', 1.307837479778843], ['ESN-80', 2.1239969867527946], ['ESN-100', 1.4380652503302187], ['ESN-120', 2.0849269689681544], ['ESN-150', 2.0469315105579873], ['ESN-200', 14.61995049569763], ['ESN-300', 53.64252693599409], ['ESN-500', 192.5343746203439], ['ESN-1000', 23.480702398181116]]\n",
      "Test Average error =  29.489239010213446\n"
     ]
    }
   ],
   "source": [
    "model_test_error = []\n",
    "test_avg_error = []\n",
    "for label in samples:\n",
    "    model_test_error.append([label,np.mean(rmse_dict[label])])\n",
    "    test_avg_error.append(np.mean(rmse_dict[label]))\n",
    "print(model_test_error)\n",
    "print(\"Test Average error = \",np.mean(test_avg_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ESN-40': 1.021261638921574, 'ESN-60': 0.5289043299427124, 'ESN-80': 1.2769176622454805, 'ESN-100': 1.0806888105470531, 'ESN-120': 2.641591192422233, 'ESN-150': 1.1894740499679881, 'ESN-200': 11.292778038486684, 'ESN-300': 34.05851894216005, 'ESN-500': 63.96118907757753, 'ESN-1000': 17.61250607088196}\n",
      "{'ESN-40': 1.453840151289397, 'ESN-60': 1.0833544858348954, 'ESN-80': 1.8841448664082783, 'ESN-100': 1.2806402020905332, 'ESN-120': 1.7847912553720777, 'ESN-150': 1.6978414255927141, 'ESN-200': 12.659072038990038, 'ESN-300': 40.75638342008179, 'ESN-500': 148.9765874832078, 'ESN-1000': 19.636961512611435}\n",
      "Train average error for ESN = 13.466382981315325\n",
      "Test average error for ESN = 23.121361684147892\n"
     ]
    }
   ],
   "source": [
    "print(rmnse_avg_train_dict)\n",
    "print(rmnse_avg_test_dict)\n",
    "error_array_test = []\n",
    "error_array_train = []\n",
    "for label in samples:\n",
    "    error_array_train.append(rmnse_avg_train_dict[label])\n",
    "    error_array_test.append(rmnse_avg_test_dict[label])\n",
    "print(\"Train average error for ESN =\", np.mean(error_array_train))\n",
    "print(\"Test average error for ESN =\", np.mean(error_array_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "samples = []\n",
    "size_values = [40, 60, 80, 100, 120, 150, 200, 300, 500, 1000]\n",
    "for size in size_values:\n",
    "    string1 = f\"ESN_pinv-RDIM_5-N_used_427-SIZE_{size}-D_10.0-RADIUS_0.9-SIGMA_1.0-DL_40-NL_0-IPL_300-REG_1e-07-NICS_3\"\n",
    "    string2 = f\"ESN-{size}\"\n",
    "    models.append([os.path.join(model_path,string1),string2])\n",
    "    samples.append(string2)\n",
    "title = \"Sea Surface Temperatures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_dict = dict()\n",
    "memory_dict = dict()\n",
    "trainable_parameters_dict = dict()\n",
    "for i in range(len(models)):\n",
    "    rfolder, label = models[i][0], models[i][1]\n",
    "    fname = os.path.join(rfolder, 'data.pickle')\n",
    "    if os.path.isfile(fname):\n",
    "        with open(fname, 'rb') as rfile:\n",
    "            try:\n",
    "                rs = pickle.load(rfile)\n",
    "            except:\n",
    "                continue\n",
    "            #print(rs.keys())\n",
    "            train_time_dict[label]=rs[\"total_training_time\"]\n",
    "            trainable_parameters_dict[label]=rs[\"n_trainable_parameters\"]\n",
    "            memory_dict[label]=rs[\"memory\"]\n",
    "    else:\n",
    "        print('Not found {}'.format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESN-40': 0.06892657279968262,\n",
       " 'ESN-60': 0.12274408340454102,\n",
       " 'ESN-80': 0.08296060562133789,\n",
       " 'ESN-100': 0.08350563049316406,\n",
       " 'ESN-120': 0.07953810691833496,\n",
       " 'ESN-150': 0.09551262855529785,\n",
       " 'ESN-200': 0.12108230590820312,\n",
       " 'ESN-300': 0.1894676685333252,\n",
       " 'ESN-500': 0.29119348526000977,\n",
       " 'ESN-1000': 0.9104361534118652}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESN-40': 96.953125,\n",
       " 'ESN-60': 97.484375,\n",
       " 'ESN-80': 98.16015625,\n",
       " 'ESN-100': 98.37890625,\n",
       " 'ESN-120': 98.734375,\n",
       " 'ESN-150': 99.328125,\n",
       " 'ESN-200': 100.21875,\n",
       " 'ESN-300': 101.94921875,\n",
       " 'ESN-500': 107.23828125,\n",
       " 'ESN-1000': 128.93359375}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESN-40': 200,\n",
       " 'ESN-60': 300,\n",
       " 'ESN-80': 400,\n",
       " 'ESN-100': 500,\n",
       " 'ESN-120': 600,\n",
       " 'ESN-150': 750,\n",
       " 'ESN-200': 1000,\n",
       " 'ESN-300': 1500,\n",
       " 'ESN-500': 2500,\n",
       " 'ESN-1000': 5000}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_parameters_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
